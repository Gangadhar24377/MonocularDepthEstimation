{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da96f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, add,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48357b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = r'C:\\Users\\vishnu\\Downloads\\monocular depth estimation\\depth estimation\\nyu_data\\nyu2_train.csv'\n",
    "\n",
    "image_filenames = []\n",
    "mask_filenames = []\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "x = 0\n",
    "for index, row in df.iterrows():\n",
    "    if x == 4000:\n",
    "        break\n",
    "    x = x + 1\n",
    "    image_path = row[0]  \n",
    "    depth_path = row[1]    \n",
    "    \n",
    "\n",
    "    image_filenames.append(\"C:/Users/vishnu/Downloads/monocular depth estimation/depth estimation/nyu_data/\"+ image_path)\n",
    "    mask_filenames.append(\"C:/Users/vishnu/Downloads/monocular depth estimation/depth estimation/nyu_data/\"+ depth_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_filenames[5])\n",
    "print(mask_filenames[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Image List:\")\n",
    "print(len(image_filenames))\n",
    "print(\"\\nDepth List:\")\n",
    "print(len(mask_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_mask(img_path, mask_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    mask = cv2.imread(mask_path)\n",
    "\n",
    "    if image is None or mask is None:\n",
    "        raise ValueError(\"Error\")\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_rgb = cv2.resize(image_rgb,(256,256))\n",
    "    mask_rgb = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    mask_rgb = cv2.resize(mask_rgb,(256,256))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(image_rgb)\n",
    "    axs[1].imshow(mask_rgb)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_mask(image_filenames[343], mask_filenames[343])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"images\": image_filenames, \"masks\": mask_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.1)\n",
    "\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8cf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image,mask):\n",
    "    image = image / 255\n",
    "    mask = mask / 255\n",
    "    return (image, mask) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(\n",
    "    data_frame,\n",
    "    batch_size,\n",
    "    augumentation_dict = {},\n",
    "    image_color_mode = \"rgb\",\n",
    "    mask_color_mode = \"grayscale\",\n",
    "    image_save_prefix = \"aug-img\",\n",
    "    mask_save_prefix = \"aug-masks\",\n",
    "    save_to_dir = None,\n",
    "    target_size = (256,256),\n",
    "    seed = 1,\n",
    "):\n",
    "    image_datagen = ImageDataGenerator(**augumentation_dict)\n",
    "    mask_datagen = ImageDataGenerator(**augumentation_dict)\n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        x_col = \"images\",\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed\n",
    "    )\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        x_col = \"masks\",\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed\n",
    "     )\n",
    "    \n",
    "    train_gen = zip(image_generator,mask_generator)\n",
    "    for image,mask in train_gen:\n",
    "        image,mask = normalize(image,mask)\n",
    "        yield (image,mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficients(y_true,y_pred, smooth = 100):\n",
    "    y_true_flatten = K.flatten(y_true)\n",
    "    y_pred_flatten = K.flatten(y_pred)\n",
    "    \n",
    "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n",
    "    \n",
    "    return (2 * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficients_loss(y_true,y_pred,smooth = 100):\n",
    "    return -dice_coefficients(y_true,y_pred,smooth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(y_true,y_pred,smooth = 100):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    sum = K.sum(y_true + y_pred)\n",
    "    iou = (intersection + smooth) / (sum - intersection + smooth)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef801a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true,y_pred):\n",
    "    y_true_flatten = K.flatten(y_true)\n",
    "    y_pred_flatten = K.flatten(y_pred)\n",
    "    \n",
    "    return -intersection_over_union(y_true_flatten,y_pred_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=100):\n",
    "    \n",
    "    # Point-wise depth\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    # Edges\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "    # Structural similarity (SSIM) index\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
    "\n",
    "    # Weights\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    w3 = theta\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048031ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Dropout, UpSampling2D\n",
    "def downsampling_block(input_tensor, n_filters):\n",
    "  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(input_tensor)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  return x\n",
    "\n",
    "def upsampling_block(input_tensor, n_filters, name, concat_with):\n",
    "  x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)\n",
    "  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convA\")(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "  x = concatenate([x, concat_with], axis=3)\n",
    "\n",
    "  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convB\")(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convC\")(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  return x\n",
    "\n",
    "def build(height, width, depth):\n",
    "  # input\n",
    "  i = Input(shape=(height, width, depth))\n",
    "\n",
    "  # encoder\n",
    "  conv1 = downsampling_block(i, 32)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  conv2 = downsampling_block(pool1, 64)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  conv3 = downsampling_block(pool2, 128)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  conv4 = downsampling_block(pool3, 256)\n",
    "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "  # bottleneck\n",
    "  conv5 = Conv2D(512, (3, 3), padding='same')(pool4)\n",
    "  conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "  conv5 = Conv2D(512, (3, 3), padding='same')(conv5)\n",
    "  conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "\n",
    "  # decoder\n",
    "  conv6 = upsampling_block(conv5, 256, \"up1\", concat_with=conv4)\n",
    "  conv7 = upsampling_block(conv6, 128, \"up2\", concat_with=conv3)\n",
    "  conv8 = upsampling_block(conv7, 64, \"up3\", concat_with=conv2)\n",
    "  conv9 = upsampling_block(conv8, 32, \"up4\", concat_with=conv1)\n",
    "\n",
    "  # output\n",
    "  o = Conv2D(filters=1, kernel_size=3, strides=(1,1), activation='sigmoid', padding='same', name='conv10')(conv9)\n",
    "\n",
    "  model = Model(inputs=i, outputs=o)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(256,256,3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544db6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height =256\n",
    "image_width = 256\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "smooth = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_loss(y_true, y_pred):\n",
    "  w1, w2, w3 = 1.0, 1.0, 0.1\n",
    "\n",
    "  l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "  dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "  dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "  l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "  l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, 1.0)) * 0.5, 0, 1)\n",
    "\n",
    "  return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\n",
    "\n",
    "#custom soft accuracy\n",
    "def depth_acc(y_true, y_pred):\n",
    "  return K.mean(K.equal(K.round(y_true), K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_param = dict(rotation_range=0.2,\n",
    "                              width_shift_range= 0.05,\n",
    "                              height_shift_range = 0.05,\n",
    "                              shear_range = 0.05,\n",
    "                              zoom_range = 0.05,\n",
    "                              horizontal_flip = True,\n",
    "                              fill_mode = 'nearest')\n",
    "train_gen = trainGenerator(df_train,BATCH_SIZE,train_generator_param)\n",
    "    \n",
    "test_gen = trainGenerator(df_val,BATCH_SIZE)\n",
    "    \n",
    "\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 10000\n",
    "decay_rate = learning_rate / EPOCHS\n",
    "\n",
    "learning_rate_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = Adam( beta_1 = 0.9,beta_2 = 0.999,learning_rate=learning_rate_schedule,amsgrad = True)\n",
    "    \n",
    "model.compile(optimizer = optimizer, loss= depth_loss, metrics = [depth_acc])\n",
    "\n",
    "callbacks = [ModelCheckpoint('depth_estimation.hdf5',verbose = 1, save_best_only = True)]\n",
    "    \n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(df_train)/BATCH_SIZE,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = test_gen,\n",
    "                    validation_steps = len(df_val) / BATCH_SIZE\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('C:/Users/vishnu/Downloads/skincancer/unet.hdf5', custom_objects = custom_objects)\n",
    "custom_objects = {\n",
    "    \"depth_loss\":depth_loss,\n",
    "    \"depth_acc\":depth_acc\n",
    "}\n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    reconstructed_model = keras.models.load_model(\"depth_estimation.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = trainGenerator(df_test, BATCH_SIZE, dict(), target_size = (image_height,image_width))\n",
    "results = reconstructed_model.evaluate(test_gen, steps=len(df_test)/BATCH_SIZE)\n",
    "\n",
    "print('Depth Loss', results[0])\n",
    "print('Depth Acc', results[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    index = np.random.randint(1, len(df_test.index))\n",
    "    img = cv2.imread(df_test['images'].iloc[index])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(image_height,image_width))\n",
    "    img = img/255\n",
    "    \n",
    "    \n",
    "    img = img[np.newaxis,:,:,:]\n",
    "    predicted_img = reconstructed_model.predict(img)\n",
    "#     predicted_img = cv2.cvtColor(predicted_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(np.squeeze(img))\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(np.squeeze(cv2.imread(df_test['masks'].iloc[index])))\n",
    "    plt.title('Original Mask')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(np.squeeze(predicted_img) > 0.5)\n",
    "    plt.title('Prediction')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd358e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
